{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL DataBase Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## connect to database\n",
    "\n",
    "path = \"Data/mlb_data.db\"\n",
    "conn = sqlite3.connect(path)\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New method - from website\n",
    "\n",
    "After browsing multiple scrapers on github, I chose to try to make my own. I decided to utilize the URL that Mr. Kessler used in his scraper (url below). I tried to make my own small loop scheme to import into a SQL database. I later realized it is similar to Mr. Kessler's. All credit for the link and method go to him and his scraper (namely, link, year/team loop idea, HTTPError catch and wait method).\n",
    "\n",
    "reference: https://github.com/alanrkessler/savantscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 Starting. Please wait (up to 5 minutes)...\n",
      "2018 Finished.\n"
     ]
    }
   ],
   "source": [
    "## year_list & team_list\n",
    "\n",
    "year_list = [2018]\n",
    "\n",
    "team_list = ['SF', 'LAD', 'ARI', 'COL', 'SD',\n",
    "             'CHC', 'MIL', 'STL', 'CIN', 'PIT',\n",
    "             'NYM', 'WSH', 'MIA', 'ATL', 'PHI',\n",
    "             'OAK', 'HOU', 'LAA', 'TEX', 'SEA',\n",
    "             'MIN', 'CWS', 'KC', 'DET', 'CLE',\n",
    "             'NYY', 'BOS', 'TB', 'TOR', 'BAL']\n",
    "\n",
    "\n",
    "## loop for each team and year\n",
    "\n",
    "for year in year_list:\n",
    "    \n",
    "    print(str(year) + ' Starting. Please wait (up to 5 minutes)...')\n",
    "\n",
    "    counter = 1      # if first team of year, replace existing table\n",
    "\n",
    "    for team in team_list:\n",
    "        done = False     # if done, stop trying to access link (stays false if error)\n",
    "                \n",
    "        while not done:\n",
    "            try:\n",
    "                link = 'https://baseballsavant.mlb.com/statcast_search/csv?all=true&hfPT=&hfAB=&hfBBT=&hfPR=' + \\\n",
    "                    '&hfZ=&stadium=&hfBBL=&hfNewZones=&hfGT=R%7C&hfC=&hfSea=' + str(year) + \\\n",
    "                    '%7C&hfSit=&player_type=pitcher&hfOuts=&opponent=&pitcher_throws=&batter_stands=&hfSA=' + \\\n",
    "                    '&game_date_gt=&game_date_lt=&team=' + team + \\\n",
    "                    '&position=&hfRO=&home_road=&hfFlag=&metric_1=&hfInn=&min_pitches=' + \\\n",
    "                    '0&min_results=0&group_by=name-event&sort_col=pitches&player_event_sort=' + \\\n",
    "                    'api_p_release_speed&sort_order=desc&min_abs=0&type=details&'\n",
    "                \n",
    "                temp = pd.read_csv(link)     # import data from link, a download csv link\n",
    "                exists = ('replace' if counter == 1 else 'append')  # if first team of year, replace existing table\n",
    "#                 print exists\n",
    "\n",
    "                temp['spray_angle'] = \\\n",
    "    (np.arctan((temp['hc_x'] - 125.42)/(198.27 - temp['hc_y']))*180/np.pi*.75).apply(lambda x: round(x, 1))\n",
    "    \n",
    "    \n",
    "                temp.to_sql(\"MLB_\" + str(year), conn, if_exists=exists, index = False)  # import to SQL\n",
    "                \n",
    "                done = True      # if import and link work, done\n",
    "                counter = counter + 1     # add to counter for each team completed\n",
    "                \n",
    "            except urllib2.HTTPError as e:     # catch an HTTP error if calling website too often\n",
    "                print(e)\n",
    "                print(str(year) + ' and ' + team + ' error...')\n",
    "                time.sleep(60)     # wait a minute before trying again\n",
    "        \n",
    "    print(str(year) + ' Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old method \n",
    "\n",
    "I manually downloaded csv files and stored them in a directory, by year. From there, I would import each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for year in range(2015, 2019):\n",
    "    \n",
    "\n",
    "#     ## current directory of data files\n",
    "\n",
    "#     cd = \"Data/savant/savant_\" + str(year) + \"/\"     # change on your machine\n",
    "\n",
    "\n",
    "#     ## create empty dataframe\n",
    "\n",
    "#     data = pd.DataFrame()\n",
    "\n",
    "\n",
    "#     ## loop through each sheet and append the previous one\n",
    "\n",
    "#     for file_name in os.listdir(cd):\n",
    "#         if 'DS' not in file_name:\n",
    "#             import_data = pd.read_csv(cd + file_name).replace(\n",
    "#                 'null', np.nan).convert_objects(convert_numeric = True)\n",
    "#             data = data.append(import_data)\n",
    "\n",
    "\n",
    "#     ## add spray angle\n",
    "\n",
    "#     data['spray_angle'] = (np.arctan((data['hc_x'] - 125.42)/(198.27 - data['hc_y']))*180/np.pi*.75).apply(lambda x: round(x, 1))\n",
    "\n",
    "\n",
    "#     # add dataframe to database\n",
    "\n",
    "#     data.to_sql(\"MLB_\" + str(year), conn, if_exists=\"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLB ID key\n",
    "\n",
    "To have a key to map names to numeric MLB player IDs.\n",
    "\n",
    "source: http://crunchtimebaseball.com/baseball_map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## current directory of data files\n",
    "\n",
    "# cd = \"http://crunchtimebaseball.com/master.csv\"     # website of linked file\n",
    "\n",
    "\n",
    "# ## create empty dataframe\n",
    "\n",
    "# data = pd.read_csv(cd, encoding = 'latin-1').replace('null', np.nan).infer_objects()\n",
    "\n",
    "\n",
    "# # add dataframe to database\n",
    "\n",
    "# data.to_sql(\"ID_Key\", conn, if_exists=\"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Checks\n",
    "\n",
    "Check to see the tables listed to confirm their existance, and see the amount of data in each season table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'ID_Key',), (u'MLB_2017',), (u'MLB_2015',), (u'MLB_2016',), (u'MLB_2018',)]\n"
     ]
    }
   ],
   "source": [
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 702440\n",
      "2016 715804\n",
      "2017 718920\n",
      "2018 129564\n"
     ]
    }
   ],
   "source": [
    "for year in [2015, 2016, 2017, 2018]:\n",
    "    df = pd.read_sql(\"\"\"SELECT game_date\n",
    "        FROM MLB_{}\n",
    "        ;\"\"\".format(year), conn)\n",
    "    print year, len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## close access to database\n",
    "\n",
    "c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
